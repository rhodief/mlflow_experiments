# Iris Classification API

FastAPI application for iris flower classification using an ONNX Random Forest model.

## Features

- **POST /predict**: Make predictions on iris flowers
- **GET /metrics**: Get API performance metrics
- **GET /model-info**: Get detailed model information
- **Interactive documentation**: Swagger UI and ReDoc

## Prerequisites

- Docker installed
- Model files generated by running the Airflow DAG (`dag_entrega_3.py`)
  - `iris_random_forest.onnx`
  - `model_asset_metadata.json`

## Quick Start

### 1. Build the Docker Image

```bash
./build.sh
```

This will create a Docker image named `iris-classification-api:latest`.

### 2. Run the API

```bash
./run.sh
```

This will:
- Start the API container on port 8000
- Mount the assets folder containing the model
- Enable auto-restart on failures

The API will be available at:
- **API**: http://localhost:8000
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## API Endpoints

### POST /predict

Make a prediction for iris species.

**Request Body:**
```json
{
  "sepal_length": 5.1,
  "sepal_width": 3.5,
  "petal_length": 1.4,
  "petal_width": 0.2
}
```

**Response:**
```json
{
  "prediction": "setosa",
  "prediction_class": 0,
  "probabilities": {
    "setosa": 0.98,
    "versicolor": 0.01,
    "virginica": 0.01
  },
  "duration_ms": 2.5,
  "timestamp": "2025-10-29T14:30:00.123456"
}
```

### GET /metrics

Get API performance metrics.

**Response:**
```json
{
  "total_predictions": 100,
  "mean_latency_ms": 2.5,
  "model_info": {
    "name": "iris_random_forest",
    "type": "RandomForestClassifier",
    "accuracy": 0.9,
    "precision": 0.902,
    "recall": 0.9,
    "f1_score": 0.899,
    "features": [
      "sepal length (cm)",
      "sepal width (cm)",
      "petal length (cm)",
      "petal width (cm)"
    ],
    "n_features": 4,
    "created_at": "2025-10-29T14:34:12.258757"
  }
}
```

### GET /model-info

Get complete model metadata.

## Testing with cURL

### Health Check
```bash
curl http://localhost:8000/
```

### Make a Prediction
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "sepal_length": 5.1,
    "sepal_width": 3.5,
    "petal_length": 1.4,
    "petal_width": 0.2
  }'
```

### Get Metrics
```bash
curl http://localhost:8000/metrics
```

## Testing with Python

```python
import requests

# Make a prediction
response = requests.post(
    "http://localhost:8000/predict",
    json={
        "sepal_length": 5.1,
        "sepal_width": 3.5,
        "petal_length": 1.4,
        "petal_width": 0.2
    }
)
print(response.json())

# Get metrics
metrics = requests.get("http://localhost:8000/metrics")
print(metrics.json())
```

## Model Information

The API uses an ONNX Random Forest model trained on the Iris dataset with:
- **Features**: 4 (sepal length, sepal width, petal length, petal width)
- **Classes**: 3 (setosa, versicolor, virginica)
- **Model Type**: RandomForestClassifier
- **Training Metrics**: See `/metrics` endpoint

## Docker Management

### View Logs
```bash
docker logs -f iris-api
```

### Stop the API
```bash
docker stop iris-api
```

### Restart the API
```bash
docker restart iris-api
```

### Remove Container
```bash
docker stop iris-api
docker rm iris-api
```

## Development

### Local Development (without Docker)

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Ensure model files are in `../assets/` directory

3. Update paths in `main.py` if needed

4. Run the API:
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

## Architecture

```
api/
├── main.py              # FastAPI application
├── requirements.txt     # Python dependencies
├── Dockerfile          # Docker image definition
├── build.sh           # Build script
├── run.sh            # Run script
└── README.md         # This file

../assets/
├── iris_random_forest.onnx       # ONNX model
└── model_asset_metadata.json     # Model metadata
```

## Performance

- Average prediction latency: ~2-5ms
- Model format: ONNX (optimized for inference)
- Concurrent requests: Supported via uvicorn workers

## Troubleshooting

### Model files not found
Ensure the Airflow DAG has been run successfully and generated:
- `iris_random_forest.onnx`
- `model_asset_metadata.json`

### Port already in use
Change the port mapping in `run.sh`:
```bash
-p 8001:8000  # Use port 8001 instead of 8000
```

### Container fails to start
Check logs:
```bash
docker logs iris-api
```

## License

Part of MLflow experiments lab project.
